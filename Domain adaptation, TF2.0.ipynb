{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uJMBb-WH2Li"
   },
   "source": [
    "# Adversarial domain adaptation in Tensorflow 2.0\n",
    "- TF2 implementation of basic adversarial technique documented here: https://arxiv.org/pdf/1409.7495.pdf\n",
    "- Source: MNIST \n",
    "- Target: MNIST-M (MNIST with random colour patches)\n",
    "- Train on MNIST and test on MNIST-M\n",
    "- Make the features of the classifier invariant to the domain to boost performance\n",
    "- Gives performance boost in accuracy on target domain from 58% to 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2MmZFz-H2Ll"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras import Model\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rVe7vz1rH2Lr",
    "outputId": "50436eca-ed1d-4309-e9ce-0cb41c53bcc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHtH9QeoH2Lv"
   },
   "outputs": [],
   "source": [
    "LOAD_FROM_PICKLE = True # True if ./mnist_m/mnist_m_test_ls.pkl file present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ojf2VxXPH2Ly"
   },
   "source": [
    "## Baseline on MNIST-M\n",
    "\n",
    "Import MNIST and convert to RGB by replicating across 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Bw_XvMklH2Lz",
    "outputId": "580f93a9-45aa-4edb-b725-99e570468e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.stack((x_train,)*3, axis=-1)\n",
    "x_test = np.stack((x_test,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYj2p5PkH2L1"
   },
   "source": [
    "Form a TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9vmGi9xlH2L2",
    "outputId": "76f94928-d84f-405c-d666-18e6965f570e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 3), (None,)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(60000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgSM2Ub_H2L4"
   },
   "source": [
    "Now MNIST-M: dataset can be obtained here: https://drive.google.com/drive/folders/0B_tExHiYS-0vR2dNZEU4NGlSSW8.\n",
    "Use imageio to read the images and crop to 28 by 28, then create a second tf dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0_djiyzH2L4"
   },
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    mnist_m_train_folder = './mnist_m/mnist_m_train/'\n",
    "    sorted_img_paths = [mnist_m_train_folder + i for i in sorted(os.listdir(mnist_m_train_folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGYFcSW9H2L6"
   },
   "outputs": [],
   "source": [
    "mnist_m_train_labels_file = './mnist_m/mnist_m_train_labels.txt'\n",
    "f = open(mnist_m_train_labels_file, \"r\")\n",
    "mnist_m_test_y = [int(i[-1]) for i in f.read().split('\\n')[:-1]]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcSU_gN1H2L7"
   },
   "outputs": [],
   "source": [
    "if LOAD_FROM_PICKLE:\n",
    "    with open(\"mnist_m/mnist_m_test_ls.pkl\", 'rb') as f:\n",
    "      mnist_m_test_ls = pickle.load(f)\n",
    "else:\n",
    "    mnist_m_test_ls = [(imageio.imread(i)[2:-2,2:-2,:]) for i in sorted_img_paths]\n",
    "    with open(\"mnist_m/mnist_m_test_ls.pkl\", 'wb') as f:\n",
    "      pickle.dump(mnist_m_test_ls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXoADtfLH2L9"
   },
   "outputs": [],
   "source": [
    "mnist_m_test_ds = tf.data.Dataset.from_tensor_slices((mnist_m_test_ls,tf.cast(mnist_m_test_y, tf.int8))).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaiqKrB9H2L-"
   },
   "source": [
    "Check some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kzb912SRH2L-"
   },
   "outputs": [],
   "source": [
    "if not LOAD_FROM_PICKLE:\n",
    "    for n in range(3):\n",
    "      image_path = sorted_img_paths[n]\n",
    "      display.display(display.Image(image_path))\n",
    "      print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0fcdiWvH2L_"
   },
   "source": [
    "Combine MNIST and MNIST-M images, to get the channel stats for normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYnyXmI7H2L_"
   },
   "outputs": [],
   "source": [
    "all_domain_images = np.vstack((x_train, mnist_m_test_ls))\n",
    "channel_mean = all_domain_images.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mf0h57juH2MB"
   },
   "outputs": [],
   "source": [
    "class BaselineModel(Model):\n",
    "  def __init__(self):\n",
    "    super(BaselineModel, self).__init__()\n",
    "    \n",
    "    self.normalise = lambda x: (tf.cast(x, tf.float64) - channel_mean) / 255.0\n",
    "    self.conv1 = Conv2D(64, 5, activation='relu')\n",
    "    self.conv2 = Conv2D(128, 5, activation='relu')\n",
    "    self.maxpool = MaxPool2D(2)\n",
    "    self.flatten = Flatten()\n",
    "    \n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "    \n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.normalise(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "\n",
    "    return self.d2(x)\n",
    "\n",
    "model = BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYlLL-ntH2MB"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djbtR-SRH2MC"
   },
   "source": [
    "Need a separate loss accumulator for each train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "669bZQ47H2MD"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "m_test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "m_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1In05mzSH2ME"
   },
   "source": [
    "Train and test ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t6ymFiMdH2ME"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFKHom14H2MF"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(mnist_images, labels, mnist_m_images, labels2):\n",
    "  predictions = model(mnist_images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "  predictions = model(mnist_m_images)\n",
    "  t_loss = loss_object(labels2, predictions)\n",
    "    \n",
    "  m_test_loss(t_loss)\n",
    "  m_test_accuracy(labels2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LZeYmDLH2MG"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    m_test_loss.reset_states()\n",
    "    m_test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7ANgVhDH2MH"
   },
   "source": [
    "Train on MNIST, evaluate on MNIST and MNIST-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9b6P89cfH2MI",
    "outputId": "b9bc2000-07cd-493b-c163-6c7216aaf421",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1, Train Accuracy: 97.08333587646484, Source Test Accuracy: 98.83000183105469, Target Test Accuracy: 61.32188415527344\n",
      "Epoch 2, Train Accuracy: 98.88166809082031, Source Test Accuracy: 99.04999542236328, Target Test Accuracy: 60.343448638916016\n",
      "Epoch 3, Train Accuracy: 99.22000122070312, Source Test Accuracy: 98.94000244140625, Target Test Accuracy: 59.12540054321289\n",
      "Epoch 4, Train Accuracy: 99.42166900634766, Source Test Accuracy: 99.04000091552734, Target Test Accuracy: 57.41813278198242\n",
      "Epoch 5, Train Accuracy: 99.54499816894531, Source Test Accuracy: 99.0199966430664, Target Test Accuracy: 58.436500549316406\n",
      "Epoch 6, Train Accuracy: 99.58666229248047, Source Test Accuracy: 99.04000091552734, Target Test Accuracy: 58.30671310424805\n",
      "Epoch 7, Train Accuracy: 99.66500091552734, Source Test Accuracy: 98.83999633789062, Target Test Accuracy: 54.7823486328125\n",
      "Epoch 8, Train Accuracy: 99.68167114257812, Source Test Accuracy: 98.97999572753906, Target Test Accuracy: 54.023563385009766\n",
      "Epoch 9, Train Accuracy: 99.71500396728516, Source Test Accuracy: 98.8699951171875, Target Test Accuracy: 51.86701583862305\n",
      "Epoch 10, Train Accuracy: 99.78333282470703, Source Test Accuracy: 99.0, Target Test Accuracy: 48.422523498535156\n",
      "Epoch 11, Train Accuracy: 99.77999877929688, Source Test Accuracy: 99.16999816894531, Target Test Accuracy: 53.7839469909668\n",
      "Epoch 12, Train Accuracy: 99.78666687011719, Source Test Accuracy: 99.02999877929688, Target Test Accuracy: 55.241615295410156\n",
      "Epoch 13, Train Accuracy: 99.80833435058594, Source Test Accuracy: 99.0999984741211, Target Test Accuracy: 57.89736557006836\n",
      "Epoch 14, Train Accuracy: 99.83999633789062, Source Test Accuracy: 98.97000122070312, Target Test Accuracy: 50.579071044921875\n",
      "Epoch 15, Train Accuracy: 99.83000183105469, Source Test Accuracy: 99.1199951171875, Target Test Accuracy: 56.13019561767578\n",
      "Epoch 16, Train Accuracy: 99.85333251953125, Source Test Accuracy: 99.12999725341797, Target Test Accuracy: 55.33146667480469\n",
      "Epoch 17, Train Accuracy: 99.875, Source Test Accuracy: 98.76000213623047, Target Test Accuracy: 50.698883056640625\n",
      "Epoch 18, Train Accuracy: 99.8566665649414, Source Test Accuracy: 99.15999603271484, Target Test Accuracy: 56.809104919433594\n",
      "Epoch 19, Train Accuracy: 99.89666748046875, Source Test Accuracy: 98.75, Target Test Accuracy: 49.34105682373047\n",
      "Epoch 20, Train Accuracy: 99.83499908447266, Source Test Accuracy: 99.0199966430664, Target Test Accuracy: 57.018768310546875\n",
      "Epoch 21, Train Accuracy: 99.87833404541016, Source Test Accuracy: 98.83999633789062, Target Test Accuracy: 51.83706283569336\n",
      "Epoch 22, Train Accuracy: 99.88999938964844, Source Test Accuracy: 98.72000122070312, Target Test Accuracy: 56.34983825683594\n",
      "Epoch 23, Train Accuracy: 99.82333374023438, Source Test Accuracy: 98.94000244140625, Target Test Accuracy: 54.88218688964844\n",
      "Epoch 24, Train Accuracy: 99.86000061035156, Source Test Accuracy: 99.0, Target Test Accuracy: 55.18171310424805\n",
      "Epoch 25, Train Accuracy: 99.92166900634766, Source Test Accuracy: 99.06999969482422, Target Test Accuracy: 55.08186721801758\n",
      "Epoch 26, Train Accuracy: 99.85832977294922, Source Test Accuracy: 99.06999969482422, Target Test Accuracy: 58.30671310424805\n",
      "Epoch 27, Train Accuracy: 99.91666412353516, Source Test Accuracy: 99.0999984741211, Target Test Accuracy: 55.76078414916992\n",
      "Epoch 28, Train Accuracy: 99.88500213623047, Source Test Accuracy: 98.91999816894531, Target Test Accuracy: 56.07028579711914\n",
      "Epoch 29, Train Accuracy: 99.90333557128906, Source Test Accuracy: 99.22000122070312, Target Test Accuracy: 54.35303497314453\n",
      "Epoch 30, Train Accuracy: 99.89833068847656, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 55.980430603027344\n",
      "Epoch 31, Train Accuracy: 99.87999725341797, Source Test Accuracy: 99.02999877929688, Target Test Accuracy: 56.37979507446289\n",
      "Epoch 32, Train Accuracy: 99.90666198730469, Source Test Accuracy: 99.19999694824219, Target Test Accuracy: 54.6825065612793\n",
      "Epoch 33, Train Accuracy: 99.9000015258789, Source Test Accuracy: 99.04000091552734, Target Test Accuracy: 53.48442077636719\n",
      "Epoch 34, Train Accuracy: 99.93167114257812, Source Test Accuracy: 99.08999633789062, Target Test Accuracy: 51.787139892578125\n",
      "Epoch 35, Train Accuracy: 99.91333770751953, Source Test Accuracy: 99.12999725341797, Target Test Accuracy: 52.555912017822266\n",
      "Epoch 36, Train Accuracy: 99.92832946777344, Source Test Accuracy: 98.97000122070312, Target Test Accuracy: 54.93210983276367\n",
      "Epoch 37, Train Accuracy: 99.91999816894531, Source Test Accuracy: 99.05999755859375, Target Test Accuracy: 55.03194808959961\n",
      "Epoch 38, Train Accuracy: 99.89833068847656, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 54.73242950439453\n",
      "Epoch 39, Train Accuracy: 99.91333770751953, Source Test Accuracy: 99.18000030517578, Target Test Accuracy: 53.045127868652344\n",
      "Epoch 40, Train Accuracy: 99.9000015258789, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 54.39297103881836\n",
      "Epoch 41, Train Accuracy: 99.91500091552734, Source Test Accuracy: 99.1199951171875, Target Test Accuracy: 54.512779235839844\n",
      "Epoch 42, Train Accuracy: 99.91666412353516, Source Test Accuracy: 98.88999938964844, Target Test Accuracy: 50.91853332519531\n",
      "Epoch 43, Train Accuracy: 99.93000030517578, Source Test Accuracy: 98.98999786376953, Target Test Accuracy: 56.170127868652344\n",
      "Epoch 44, Train Accuracy: 99.9383316040039, Source Test Accuracy: 99.05999755859375, Target Test Accuracy: 54.88218688964844\n",
      "Epoch 45, Train Accuracy: 99.92832946777344, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 49.46086502075195\n",
      "Epoch 46, Train Accuracy: 99.93499755859375, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 52.805511474609375\n",
      "Epoch 47, Train Accuracy: 99.94833374023438, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 55.22164535522461\n",
      "Epoch 48, Train Accuracy: 99.91000366210938, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 54.61261749267578\n",
      "Epoch 49, Train Accuracy: 99.93666076660156, Source Test Accuracy: 98.95999908447266, Target Test Accuracy: 56.569488525390625\n",
      "Epoch 50, Train Accuracy: 99.94666290283203, Source Test Accuracy: 99.20999908447266, Target Test Accuracy: 56.829071044921875\n",
      "Epoch 51, Train Accuracy: 99.94000244140625, Source Test Accuracy: 99.04999542236328, Target Test Accuracy: 58.94568634033203\n",
      "Epoch 52, Train Accuracy: 99.96333312988281, Source Test Accuracy: 99.08000183105469, Target Test Accuracy: 58.047122955322266\n",
      "Epoch 53, Train Accuracy: 99.93666076660156, Source Test Accuracy: 98.8699951171875, Target Test Accuracy: 52.256385803222656\n",
      "Epoch 54, Train Accuracy: 99.91500091552734, Source Test Accuracy: 98.90999603271484, Target Test Accuracy: 53.045127868652344\n",
      "Epoch 55, Train Accuracy: 99.9433364868164, Source Test Accuracy: 99.04999542236328, Target Test Accuracy: 50.329471588134766\n",
      "Epoch 56, Train Accuracy: 99.93333435058594, Source Test Accuracy: 99.01000213623047, Target Test Accuracy: 56.21006393432617\n",
      "Epoch 57, Train Accuracy: 99.96499633789062, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 54.94209671020508\n",
      "Epoch 58, Train Accuracy: 99.91666412353516, Source Test Accuracy: 99.01000213623047, Target Test Accuracy: 57.55790328979492\n",
      "Epoch 59, Train Accuracy: 99.94000244140625, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 55.08186721801758\n",
      "Epoch 60, Train Accuracy: 99.94000244140625, Source Test Accuracy: 99.18000030517578, Target Test Accuracy: 55.18171310424805\n",
      "Epoch 61, Train Accuracy: 99.9749984741211, Source Test Accuracy: 99.0999984741211, Target Test Accuracy: 56.25998306274414\n",
      "Epoch 62, Train Accuracy: 99.92166900634766, Source Test Accuracy: 99.1199951171875, Target Test Accuracy: 53.953670501708984\n",
      "Epoch 63, Train Accuracy: 99.95999908447266, Source Test Accuracy: 99.27999877929688, Target Test Accuracy: 55.75080108642578\n",
      "Epoch 64, Train Accuracy: 99.93167114257812, Source Test Accuracy: 99.06999969482422, Target Test Accuracy: 56.1601448059082\n",
      "Epoch 65, Train Accuracy: 99.92666625976562, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 55.27156448364258\n",
      "Epoch 66, Train Accuracy: 99.95832824707031, Source Test Accuracy: 99.08000183105469, Target Test Accuracy: 52.76557922363281\n",
      "Epoch 67, Train Accuracy: 99.9433364868164, Source Test Accuracy: 98.97000122070312, Target Test Accuracy: 54.90215301513672\n",
      "Epoch 68, Train Accuracy: 99.94499969482422, Source Test Accuracy: 99.08999633789062, Target Test Accuracy: 54.04353332519531\n",
      "Epoch 69, Train Accuracy: 99.95166778564453, Source Test Accuracy: 98.93000030517578, Target Test Accuracy: 54.60263442993164\n",
      "Epoch 70, Train Accuracy: 99.95166778564453, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 56.14017868041992\n",
      "Epoch 71, Train Accuracy: 99.94499969482422, Source Test Accuracy: 98.95999908447266, Target Test Accuracy: 56.20008087158203\n",
      "Epoch 72, Train Accuracy: 99.95999908447266, Source Test Accuracy: 99.23999786376953, Target Test Accuracy: 56.998802185058594\n",
      "Epoch 73, Train Accuracy: 99.9766616821289, Source Test Accuracy: 99.06999969482422, Target Test Accuracy: 55.9704475402832\n",
      "Epoch 74, Train Accuracy: 99.93499755859375, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 53.13498306274414\n",
      "Epoch 75, Train Accuracy: 99.94166564941406, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 56.02036666870117\n",
      "Epoch 76, Train Accuracy: 99.94999694824219, Source Test Accuracy: 99.15999603271484, Target Test Accuracy: 55.85063552856445\n",
      "Epoch 77, Train Accuracy: 99.95500183105469, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 55.311500549316406\n",
      "Epoch 78, Train Accuracy: 99.94999694824219, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 56.79911804199219\n",
      "Epoch 79, Train Accuracy: 99.96499633789062, Source Test Accuracy: 99.0199966430664, Target Test Accuracy: 55.39137268066406\n",
      "Epoch 80, Train Accuracy: 99.94499969482422, Source Test Accuracy: 99.16999816894531, Target Test Accuracy: 55.660945892333984\n",
      "Epoch 81, Train Accuracy: 99.95333862304688, Source Test Accuracy: 99.16999816894531, Target Test Accuracy: 55.7807502746582\n",
      "Epoch 82, Train Accuracy: 99.95333862304688, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 55.86062240600586\n",
      "Epoch 83, Train Accuracy: 99.96499633789062, Source Test Accuracy: 99.08000183105469, Target Test Accuracy: 56.40974807739258\n",
      "Epoch 84, Train Accuracy: 99.95166778564453, Source Test Accuracy: 99.19999694824219, Target Test Accuracy: 54.70248031616211\n",
      "Epoch 85, Train Accuracy: 99.96333312988281, Source Test Accuracy: 99.15999603271484, Target Test Accuracy: 55.121803283691406\n",
      "Epoch 86, Train Accuracy: 99.99166870117188, Source Test Accuracy: 99.26000213623047, Target Test Accuracy: 54.67251968383789\n",
      "Epoch 87, Train Accuracy: 99.96499633789062, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 56.92891311645508\n",
      "Epoch 88, Train Accuracy: 99.95999908447266, Source Test Accuracy: 99.19999694824219, Target Test Accuracy: 57.35823059082031\n",
      "Epoch 89, Train Accuracy: 99.94999694824219, Source Test Accuracy: 99.22000122070312, Target Test Accuracy: 55.4013557434082\n",
      "Epoch 90, Train Accuracy: 99.96833038330078, Source Test Accuracy: 99.12999725341797, Target Test Accuracy: 58.14696502685547\n",
      "Epoch 91, Train Accuracy: 99.94499969482422, Source Test Accuracy: 99.20999908447266, Target Test Accuracy: 58.276756286621094\n",
      "Epoch 92, Train Accuracy: 99.98333740234375, Source Test Accuracy: 99.19999694824219, Target Test Accuracy: 55.33146667480469\n",
      "Epoch 93, Train Accuracy: 99.97333526611328, Source Test Accuracy: 99.04000091552734, Target Test Accuracy: 56.40974807739258\n",
      "Epoch 94, Train Accuracy: 99.95832824707031, Source Test Accuracy: 99.13999938964844, Target Test Accuracy: 58.7160530090332\n",
      "Epoch 95, Train Accuracy: 99.96333312988281, Source Test Accuracy: 99.11000061035156, Target Test Accuracy: 58.047122955322266\n",
      "Epoch 96, Train Accuracy: 99.95832824707031, Source Test Accuracy: 99.0, Target Test Accuracy: 56.00040054321289\n",
      "Epoch 97, Train Accuracy: 99.9766616821289, Source Test Accuracy: 99.08000183105469, Target Test Accuracy: 58.10702896118164\n",
      "Epoch 98, Train Accuracy: 99.94166564941406, Source Test Accuracy: 99.1500015258789, Target Test Accuracy: 58.686100006103516\n",
      "Epoch 99, Train Accuracy: 99.9800033569336, Source Test Accuracy: 99.15999603271484, Target Test Accuracy: 57.83746337890625\n",
      "Epoch 100, Train Accuracy: 99.98500061035156, Source Test Accuracy: 99.02999877929688, Target Test Accuracy: 56.00040054321289\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  reset_metrics()\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_data, m_test_data in zip(test_ds,mnist_m_test_ds):\n",
    "    test_step(test_data[0], test_data[1], m_test_data[0], m_test_data[1])\n",
    "    \n",
    "  template = 'Epoch {}, Train Accuracy: {}, Source Test Accuracy: {}, Target Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_accuracy.result()*100,\n",
    "                         m_test_accuracy.result()*100,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhE3yGd2H2MJ"
   },
   "source": [
    "## Domain confusion\n",
    "Build separate components so that distinct sets of gradients are easily accessed:\n",
    "\n",
    "- feature generator\n",
    "- label classifier \n",
    "- domain classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Vb4mGKwH2MJ"
   },
   "outputs": [],
   "source": [
    "class FeatureGenerator(Model):\n",
    "  def __init__(self):\n",
    "    super(FeatureGenerator, self).__init__() \n",
    "    self.normalise = lambda x: (tf.cast(x, tf.float64) - channel_mean) / 255.0\n",
    "    self.conv1 = Conv2D(64, 5, activation='relu')\n",
    "    self.conv2 = Conv2D(128, 5, activation='relu')\n",
    "    self.maxpool = MaxPool2D(2)\n",
    "    self.flatten = Flatten()\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.normalise(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.maxpool(x)\n",
    "\n",
    "    return self.flatten(x)\n",
    "\n",
    "feature_generator = FeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OqlhZtxH2MK"
   },
   "outputs": [],
   "source": [
    "class LabelPredictor(Model):\n",
    "  def __init__(self):\n",
    "    super(LabelPredictor, self).__init__() \n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "    \n",
    "\n",
    "  def call(self, feats):  \n",
    "    feats = self.d1(feats)\n",
    "\n",
    "    return self.d2(feats)\n",
    "\n",
    "label_predictor = LabelPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTC5gqXkH2ML"
   },
   "outputs": [],
   "source": [
    "class DomainPredictor(Model):\n",
    "  def __init__(self):\n",
    "    super(DomainPredictor, self).__init__()   \n",
    "    self.d3 = Dense(64, activation='relu')\n",
    "    self.d4 = Dense(2, activation='softmax')\n",
    "\n",
    "  def call(self, feats):\n",
    "    feats = self.d3(feats)\n",
    "    \n",
    "    return self.d4(feats)\n",
    "\n",
    "domain_predictor = DomainPredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAvHvQHFH2MM"
   },
   "source": [
    "Make second training dataset of MNIST and MNIST-M images and their respective domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHeWfO05H2MM"
   },
   "outputs": [],
   "source": [
    "x_train_domain_labels = np.ones([len(x_train)])\n",
    "mnist_m_domain_labels = np.zeros([len(mnist_m_test_ls)])\n",
    "all_domain_labels = np.hstack((x_train_domain_labels, mnist_m_domain_labels))\n",
    "\n",
    "domain_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (all_domain_images, tf.cast(all_domain_labels, tf.int8))).shuffle(60000).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VD5Qut4rH2MN"
   },
   "source": [
    "Separate optimizers to allow different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3FZ426LH2MP"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "f_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buvyN3xdH2MQ"
   },
   "source": [
    "Discriminative losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6zuB2oaH2MQ"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "m_test_loss = tf.keras.metrics.Mean(name='m_test_loss')\n",
    "m_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='m_test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OSgakEbH2MR"
   },
   "source": [
    "Confusion loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AhcL5FaH2MR"
   },
   "outputs": [],
   "source": [
    "conf_train_loss = tf.keras.metrics.Mean(name='c_train_loss')\n",
    "conf_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='c_train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGeFl1tbH2MS"
   },
   "source": [
    "## Adversarial loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qTugzn7H2MS"
   },
   "source": [
    "There are three sets of parameters to update, one for each component of the model. Label and domain classifiers are updated in the usual way. Parameters of the feature generator are updated using the standard gradient backpropagated from the label classifier, summed with the reverse of the gradient from the domain classifier; the feature generator learns to confound the domain classifier, resulting in domain invariant features which should be useful for general performance.\n",
    "\n",
    "\n",
    "<img src=\"DANN_architecture.png\" style=\"width: 600px;\">\n",
    "\n",
    "\n",
    "Image taken from: https://arxiv.org/pdf/1409.7495.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jfXBTueH2MS"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels, images2, domains, alpha):\n",
    "    \n",
    "  \"\"\"\n",
    "  i. images = batch of source images\n",
    "  ii. labels = corresponding labels\n",
    "  iii. images2 = batch of source and target images\n",
    "  iv. domains = corresponding domain labels\n",
    "  v. alpha = weight attributed to the domain loss\n",
    "  \"\"\"\n",
    "    \n",
    "  ## Update the generator and the classifier\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    features = feature_generator(images)\n",
    "    l_predictions = label_predictor(features)\n",
    "    features = feature_generator(images2)\n",
    "    d_predictions = domain_predictor(features)\n",
    "    label_loss = loss_object(labels, l_predictions)\n",
    "    domain_loss = loss_object(domains, d_predictions)\n",
    "    \n",
    "  f_gradients_on_label_loss = tape.gradient(label_loss, feature_generator.trainable_variables)\n",
    "  f_gradients_on_domain_loss = tape.gradient(domain_loss, feature_generator.trainable_variables)    \n",
    "  f_gradients = [f_gradients_on_label_loss[i] - alpha*f_gradients_on_domain_loss[\n",
    "      i] for i in range(len(f_gradients_on_domain_loss))]\n",
    "\n",
    "    \n",
    "  l_gradients = tape.gradient(label_loss, label_predictor.trainable_variables)\n",
    "\n",
    "  f_optimizer.apply_gradients(zip(f_gradients+l_gradients, \n",
    "                                  feature_generator.trainable_variables+label_predictor.trainable_variables)) \n",
    "    \n",
    "    \n",
    "  ## Update the discriminator: Comment this bit to complete all updates in one step. Asynchronous updating \n",
    "  ## seems to work a bit better, with better accuracy and stability, but may take longer to train    \n",
    "  with tf.GradientTape() as tape:\n",
    "    features = feature_generator(images2)\n",
    "    d_predictions = domain_predictor(features)\n",
    "    domain_loss = loss_object(domains, d_predictions)\n",
    "  #####\n",
    "   \n",
    "  d_gradients = tape.gradient(domain_loss, domain_predictor.trainable_variables)  \n",
    "  d_gradients = [alpha*i for i in d_gradients]\n",
    "  d_optimizer.apply_gradients(zip(d_gradients, domain_predictor.trainable_variables))\n",
    "  \n",
    "    \n",
    "    \n",
    "  train_loss(label_loss)\n",
    "  train_accuracy(labels, l_predictions)\n",
    "  conf_train_loss(domain_loss)\n",
    "  conf_train_accuracy(domains, d_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-8GONwqH2MT"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(mnist_images, labels, mnist_m_images, labels2):\n",
    "  features = feature_generator(mnist_images)\n",
    "  predictions = label_predictor(features)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "  features = feature_generator(mnist_m_images)\n",
    "  predictions = label_predictor(features)\n",
    "  t_loss = loss_object(labels2, predictions)\n",
    "    \n",
    "  m_test_loss(t_loss)\n",
    "  m_test_accuracy(labels2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1YDFxqdH2MU"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    m_test_loss.reset_states()\n",
    "    m_test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80DLte96H2MV"
   },
   "source": [
    "Train and evaluate. May need > 100 epochs for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TAEV-vrfH2MV",
    "outputId": "57f89b15-08e9-43cd-9e1a-61131c973e3e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1, Train Accuracy: 83.44166564941406, Domain Accuracy: 71.45333099365234, Source Test Accuracy: 94.38999938964844, Target Test Accuracy: 61.08226776123047\n",
      "Epoch 2, Train Accuracy: 94.00833129882812, Domain Accuracy: 73.0999984741211, Source Test Accuracy: 95.85000610351562, Target Test Accuracy: 66.81310272216797\n",
      "Epoch 3, Train Accuracy: 95.5566635131836, Domain Accuracy: 72.9183349609375, Source Test Accuracy: 96.01000213623047, Target Test Accuracy: 72.77356719970703\n",
      "Epoch 4, Train Accuracy: 96.24166870117188, Domain Accuracy: 72.71958923339844, Source Test Accuracy: 97.08000183105469, Target Test Accuracy: 75.11980438232422\n",
      "Epoch 5, Train Accuracy: 96.80999755859375, Domain Accuracy: 72.7836685180664, Source Test Accuracy: 96.5, Target Test Accuracy: 76.80711364746094\n",
      "Epoch 6, Train Accuracy: 97.04000091552734, Domain Accuracy: 72.82222747802734, Source Test Accuracy: 96.63999938964844, Target Test Accuracy: 77.0467300415039\n",
      "Epoch 7, Train Accuracy: 97.27166748046875, Domain Accuracy: 72.71881103515625, Source Test Accuracy: 96.4800033569336, Target Test Accuracy: 75.80870056152344\n",
      "Epoch 8, Train Accuracy: 97.39166259765625, Domain Accuracy: 72.609375, Source Test Accuracy: 96.88999938964844, Target Test Accuracy: 78.92372131347656\n",
      "Epoch 9, Train Accuracy: 97.68000030517578, Domain Accuracy: 72.46111297607422, Source Test Accuracy: 96.97000122070312, Target Test Accuracy: 80.65096282958984\n",
      "Epoch 10, Train Accuracy: 97.63999938964844, Domain Accuracy: 72.36316680908203, Source Test Accuracy: 96.24000549316406, Target Test Accuracy: 78.4544677734375\n",
      "Epoch 11, Train Accuracy: 97.66999816894531, Domain Accuracy: 72.24620819091797, Source Test Accuracy: 95.36000061035156, Target Test Accuracy: 69.32907104492188\n",
      "Epoch 12, Train Accuracy: 97.9433364868164, Domain Accuracy: 72.22041320800781, Source Test Accuracy: 97.50999450683594, Target Test Accuracy: 81.21006774902344\n",
      "Epoch 13, Train Accuracy: 97.96666717529297, Domain Accuracy: 72.17512512207031, Source Test Accuracy: 96.52999877929688, Target Test Accuracy: 76.16812896728516\n",
      "Epoch 14, Train Accuracy: 97.98833465576172, Domain Accuracy: 72.16893005371094, Source Test Accuracy: 96.95999908447266, Target Test Accuracy: 78.74401092529297\n",
      "Epoch 15, Train Accuracy: 98.05833435058594, Domain Accuracy: 72.16389465332031, Source Test Accuracy: 97.43999481201172, Target Test Accuracy: 81.2599868774414\n",
      "Epoch 16, Train Accuracy: 98.09166717529297, Domain Accuracy: 72.09385681152344, Source Test Accuracy: 97.7699966430664, Target Test Accuracy: 82.22843170166016\n",
      "Epoch 17, Train Accuracy: 98.07333374023438, Domain Accuracy: 72.06343078613281, Source Test Accuracy: 97.36000061035156, Target Test Accuracy: 81.41973114013672\n",
      "Epoch 18, Train Accuracy: 98.19166564941406, Domain Accuracy: 72.08379364013672, Source Test Accuracy: 97.25999450683594, Target Test Accuracy: 80.51118469238281\n",
      "Epoch 19, Train Accuracy: 98.31832885742188, Domain Accuracy: 72.1053466796875, Source Test Accuracy: 96.98999786376953, Target Test Accuracy: 81.36980438232422\n",
      "Epoch 20, Train Accuracy: 98.32833099365234, Domain Accuracy: 72.09516906738281, Source Test Accuracy: 96.6300048828125, Target Test Accuracy: 82.55790710449219\n",
      "Epoch 21, Train Accuracy: 98.4383316040039, Domain Accuracy: 72.11674499511719, Source Test Accuracy: 97.5199966430664, Target Test Accuracy: 83.88578033447266\n",
      "Epoch 22, Train Accuracy: 98.55999755859375, Domain Accuracy: 72.1308364868164, Source Test Accuracy: 97.15999603271484, Target Test Accuracy: 83.88578033447266\n",
      "Epoch 23, Train Accuracy: 98.39833068847656, Domain Accuracy: 72.12435150146484, Source Test Accuracy: 97.25, Target Test Accuracy: 82.46804809570312\n",
      "Epoch 24, Train Accuracy: 98.61500549316406, Domain Accuracy: 72.1436767578125, Source Test Accuracy: 97.02999877929688, Target Test Accuracy: 83.18689727783203\n",
      "Epoch 25, Train Accuracy: 98.59333038330078, Domain Accuracy: 72.16326904296875, Source Test Accuracy: 97.91999816894531, Target Test Accuracy: 84.69448852539062\n",
      "Epoch 26, Train Accuracy: 98.46833038330078, Domain Accuracy: 72.17903900146484, Source Test Accuracy: 97.05999755859375, Target Test Accuracy: 84.69448852539062\n",
      "Epoch 27, Train Accuracy: 98.58999633789062, Domain Accuracy: 72.15240478515625, Source Test Accuracy: 96.95999908447266, Target Test Accuracy: 83.41653442382812\n",
      "Epoch 28, Train Accuracy: 98.61833190917969, Domain Accuracy: 72.1403579711914, Source Test Accuracy: 97.90999603271484, Target Test Accuracy: 84.92411804199219\n",
      "Epoch 29, Train Accuracy: 98.53333282470703, Domain Accuracy: 72.12310791015625, Source Test Accuracy: 97.29999542236328, Target Test Accuracy: 85.48323059082031\n",
      "Epoch 30, Train Accuracy: 98.7066650390625, Domain Accuracy: 72.12305450439453, Source Test Accuracy: 97.15999603271484, Target Test Accuracy: 84.85423278808594\n",
      "Epoch 31, Train Accuracy: 98.52999877929688, Domain Accuracy: 72.0444107055664, Source Test Accuracy: 97.64999389648438, Target Test Accuracy: 83.7659683227539\n",
      "Epoch 32, Train Accuracy: 98.788330078125, Domain Accuracy: 72.01250457763672, Source Test Accuracy: 97.45999908447266, Target Test Accuracy: 86.39176940917969\n",
      "Epoch 33, Train Accuracy: 98.76000213623047, Domain Accuracy: 72.0124740600586, Source Test Accuracy: 97.05999755859375, Target Test Accuracy: 83.69608306884766\n",
      "Epoch 34, Train Accuracy: 98.64500427246094, Domain Accuracy: 72.00686645507812, Source Test Accuracy: 97.70999908447266, Target Test Accuracy: 85.01397705078125\n",
      "Epoch 35, Train Accuracy: 98.8133316040039, Domain Accuracy: 72.0057601928711, Source Test Accuracy: 97.36000061035156, Target Test Accuracy: 85.48323059082031\n",
      "Epoch 36, Train Accuracy: 98.80500030517578, Domain Accuracy: 72.00828552246094, Source Test Accuracy: 97.53999328613281, Target Test Accuracy: 86.25199890136719\n",
      "Epoch 37, Train Accuracy: 98.8116683959961, Domain Accuracy: 72.01256561279297, Source Test Accuracy: 97.72999572753906, Target Test Accuracy: 85.55311584472656\n",
      "Epoch 38, Train Accuracy: 98.77666473388672, Domain Accuracy: 72.01438903808594, Source Test Accuracy: 97.22000122070312, Target Test Accuracy: 85.14376831054688\n",
      "Epoch 39, Train Accuracy: 98.88999938964844, Domain Accuracy: 72.02897644042969, Source Test Accuracy: 97.5, Target Test Accuracy: 86.16213989257812\n",
      "Epoch 40, Train Accuracy: 98.88500213623047, Domain Accuracy: 72.02079010009766, Source Test Accuracy: 97.83999633789062, Target Test Accuracy: 86.65135192871094\n",
      "Epoch 41, Train Accuracy: 98.89167022705078, Domain Accuracy: 72.02958679199219, Source Test Accuracy: 97.29999542236328, Target Test Accuracy: 86.70127868652344\n",
      "Epoch 42, Train Accuracy: 98.79833221435547, Domain Accuracy: 72.02349090576172, Source Test Accuracy: 97.2699966430664, Target Test Accuracy: 86.50160217285156\n",
      "Epoch 43, Train Accuracy: 99.0, Domain Accuracy: 72.02926635742188, Source Test Accuracy: 97.48999786376953, Target Test Accuracy: 87.08067321777344\n",
      "Epoch 44, Train Accuracy: 98.97666931152344, Domain Accuracy: 72.03572082519531, Source Test Accuracy: 97.73999786376953, Target Test Accuracy: 86.10223388671875\n",
      "Epoch 45, Train Accuracy: 98.94833374023438, Domain Accuracy: 72.04588317871094, Source Test Accuracy: 97.57999420166016, Target Test Accuracy: 84.61461639404297\n",
      "Epoch 46, Train Accuracy: 99.08333587646484, Domain Accuracy: 72.05087280273438, Source Test Accuracy: 97.04000091552734, Target Test Accuracy: 86.67132568359375\n",
      "Epoch 47, Train Accuracy: 98.98832702636719, Domain Accuracy: 72.06180572509766, Source Test Accuracy: 97.62999725341797, Target Test Accuracy: 86.53154754638672\n",
      "Epoch 48, Train Accuracy: 99.03666687011719, Domain Accuracy: 72.06791687011719, Source Test Accuracy: 97.39999389648438, Target Test Accuracy: 86.77116394042969\n",
      "Epoch 49, Train Accuracy: 99.0616683959961, Domain Accuracy: 72.06558227539062, Source Test Accuracy: 97.41999816894531, Target Test Accuracy: 86.68131256103516\n",
      "Epoch 50, Train Accuracy: 99.01499938964844, Domain Accuracy: 72.06316375732422, Source Test Accuracy: 97.58999633789062, Target Test Accuracy: 85.3134994506836\n",
      "Epoch 51, Train Accuracy: 99.0999984741211, Domain Accuracy: 72.0704574584961, Source Test Accuracy: 97.58999633789062, Target Test Accuracy: 86.15215301513672\n",
      "Epoch 52, Train Accuracy: 99.06500244140625, Domain Accuracy: 72.0777587890625, Source Test Accuracy: 97.37999725341797, Target Test Accuracy: 85.79273223876953\n",
      "Epoch 53, Train Accuracy: 99.01166534423828, Domain Accuracy: 72.08185577392578, Source Test Accuracy: 97.56999969482422, Target Test Accuracy: 87.13058471679688\n",
      "Epoch 54, Train Accuracy: 99.07666778564453, Domain Accuracy: 72.0901870727539, Source Test Accuracy: 97.68999481201172, Target Test Accuracy: 86.41173553466797\n",
      "Epoch 55, Train Accuracy: 99.11500549316406, Domain Accuracy: 72.09278869628906, Source Test Accuracy: 97.93000030517578, Target Test Accuracy: 87.689697265625\n",
      "Epoch 56, Train Accuracy: 99.06500244140625, Domain Accuracy: 72.07919311523438, Source Test Accuracy: 97.33999633789062, Target Test Accuracy: 86.52156829833984\n",
      "Epoch 57, Train Accuracy: 99.15666198730469, Domain Accuracy: 72.08444213867188, Source Test Accuracy: 97.44999694824219, Target Test Accuracy: 87.14057922363281\n",
      "Epoch 58, Train Accuracy: 99.22999572753906, Domain Accuracy: 72.09861755371094, Source Test Accuracy: 97.13999938964844, Target Test Accuracy: 87.61980438232422\n",
      "Epoch 59, Train Accuracy: 99.1500015258789, Domain Accuracy: 72.10016632080078, Source Test Accuracy: 97.47999572753906, Target Test Accuracy: 85.6529541015625\n",
      "Epoch 60, Train Accuracy: 99.07500457763672, Domain Accuracy: 72.1114730834961, Source Test Accuracy: 97.40999603271484, Target Test Accuracy: 87.29033660888672\n",
      "Epoch 61, Train Accuracy: 99.2750015258789, Domain Accuracy: 72.09961700439453, Source Test Accuracy: 97.82999420166016, Target Test Accuracy: 86.68131256103516\n",
      "Epoch 62, Train Accuracy: 99.22000122070312, Domain Accuracy: 72.09083557128906, Source Test Accuracy: 97.40999603271484, Target Test Accuracy: 88.22883605957031\n",
      "Epoch 63, Train Accuracy: 99.18500518798828, Domain Accuracy: 72.09492492675781, Source Test Accuracy: 97.64999389648438, Target Test Accuracy: 88.2488021850586\n",
      "Epoch 64, Train Accuracy: 99.22833251953125, Domain Accuracy: 72.09247589111328, Source Test Accuracy: 97.0, Target Test Accuracy: 86.2220458984375\n",
      "Epoch 65, Train Accuracy: 99.21833038330078, Domain Accuracy: 72.08964538574219, Source Test Accuracy: 97.2699966430664, Target Test Accuracy: 87.60982513427734\n",
      "Epoch 66, Train Accuracy: 99.33333587646484, Domain Accuracy: 72.0861587524414, Source Test Accuracy: 97.47000122070312, Target Test Accuracy: 87.46006774902344\n",
      "Epoch 67, Train Accuracy: 99.2316665649414, Domain Accuracy: 72.0882568359375, Source Test Accuracy: 97.23999786376953, Target Test Accuracy: 87.71965026855469\n",
      "Epoch 68, Train Accuracy: 99.2750015258789, Domain Accuracy: 72.088134765625, Source Test Accuracy: 97.43999481201172, Target Test Accuracy: 88.2088623046875\n",
      "Epoch 69, Train Accuracy: 99.18333435058594, Domain Accuracy: 72.09425354003906, Source Test Accuracy: 97.54999542236328, Target Test Accuracy: 88.66812896728516\n",
      "Epoch 70, Train Accuracy: 99.29166412353516, Domain Accuracy: 72.10009765625, Source Test Accuracy: 97.55999755859375, Target Test Accuracy: 87.56988525390625\n",
      "Epoch 71, Train Accuracy: 99.288330078125, Domain Accuracy: 72.11046600341797, Source Test Accuracy: 97.52999877929688, Target Test Accuracy: 87.90934753417969\n",
      "Epoch 72, Train Accuracy: 99.23999786376953, Domain Accuracy: 72.11157989501953, Source Test Accuracy: 97.61000061035156, Target Test Accuracy: 88.30870056152344\n",
      "Epoch 73, Train Accuracy: 99.35832977294922, Domain Accuracy: 72.11618041992188, Source Test Accuracy: 97.62999725341797, Target Test Accuracy: 87.26038360595703\n",
      "Epoch 74, Train Accuracy: 99.24500274658203, Domain Accuracy: 72.12239074707031, Source Test Accuracy: 97.6199951171875, Target Test Accuracy: 88.53833770751953\n",
      "Epoch 75, Train Accuracy: 99.41666412353516, Domain Accuracy: 72.12675476074219, Source Test Accuracy: 97.45999908447266, Target Test Accuracy: 86.50160217285156\n",
      "Epoch 76, Train Accuracy: 99.21333312988281, Domain Accuracy: 72.1348876953125, Source Test Accuracy: 97.68000030517578, Target Test Accuracy: 87.40016174316406\n",
      "Epoch 77, Train Accuracy: 99.38999938964844, Domain Accuracy: 72.14525604248047, Source Test Accuracy: 97.13999938964844, Target Test Accuracy: 87.38019561767578\n",
      "Epoch 78, Train Accuracy: 99.35832977294922, Domain Accuracy: 72.15316009521484, Source Test Accuracy: 97.5999984741211, Target Test Accuracy: 88.827880859375\n",
      "Epoch 79, Train Accuracy: 99.32666778564453, Domain Accuracy: 72.1582260131836, Source Test Accuracy: 97.39999389648438, Target Test Accuracy: 88.17891693115234\n",
      "Epoch 80, Train Accuracy: 99.45166778564453, Domain Accuracy: 72.16343688964844, Source Test Accuracy: 97.47000122070312, Target Test Accuracy: 88.03913879394531\n",
      "Epoch 81, Train Accuracy: 99.37833404541016, Domain Accuracy: 72.17572021484375, Source Test Accuracy: 97.87999725341797, Target Test Accuracy: 88.47843170166016\n",
      "Epoch 82, Train Accuracy: 99.42500305175781, Domain Accuracy: 72.18656921386719, Source Test Accuracy: 97.29000091552734, Target Test Accuracy: 88.6281967163086\n",
      "Epoch 83, Train Accuracy: 99.40166473388672, Domain Accuracy: 72.19877624511719, Source Test Accuracy: 97.5199966430664, Target Test Accuracy: 87.48003387451172\n",
      "Epoch 84, Train Accuracy: 99.42666625976562, Domain Accuracy: 72.20561218261719, Source Test Accuracy: 97.58999633789062, Target Test Accuracy: 88.31868743896484\n",
      "Epoch 85, Train Accuracy: 99.47000122070312, Domain Accuracy: 72.21726989746094, Source Test Accuracy: 97.50999450683594, Target Test Accuracy: 87.47004699707031\n",
      "Epoch 86, Train Accuracy: 99.39833068847656, Domain Accuracy: 72.23023223876953, Source Test Accuracy: 97.52999877929688, Target Test Accuracy: 87.8294677734375\n",
      "Epoch 87, Train Accuracy: 99.48500061035156, Domain Accuracy: 72.23706817626953, Source Test Accuracy: 97.5, Target Test Accuracy: 88.45846557617188\n",
      "Epoch 88, Train Accuracy: 99.41500091552734, Domain Accuracy: 72.24430084228516, Source Test Accuracy: 97.52999877929688, Target Test Accuracy: 88.34864807128906\n",
      "Epoch 89, Train Accuracy: 99.44999694824219, Domain Accuracy: 72.2528076171875, Source Test Accuracy: 97.8499984741211, Target Test Accuracy: 88.79792022705078\n",
      "Epoch 90, Train Accuracy: 99.44499969482422, Domain Accuracy: 72.26448059082031, Source Test Accuracy: 97.61000061035156, Target Test Accuracy: 87.1106185913086\n",
      "Epoch 91, Train Accuracy: 99.47166442871094, Domain Accuracy: 72.26754760742188, Source Test Accuracy: 97.5199966430664, Target Test Accuracy: 88.07907104492188\n",
      "Epoch 92, Train Accuracy: 99.4383316040039, Domain Accuracy: 72.27951049804688, Source Test Accuracy: 97.5, Target Test Accuracy: 88.53833770751953\n",
      "Epoch 93, Train Accuracy: 99.49500274658203, Domain Accuracy: 72.28890991210938, Source Test Accuracy: 97.56999969482422, Target Test Accuracy: 88.52835083007812\n",
      "Epoch 94, Train Accuracy: 99.40333557128906, Domain Accuracy: 72.28840637207031, Source Test Accuracy: 97.52999877929688, Target Test Accuracy: 88.7679672241211\n",
      "Epoch 95, Train Accuracy: 99.49333190917969, Domain Accuracy: 72.29830169677734, Source Test Accuracy: 97.64999389648438, Target Test Accuracy: 87.76956939697266\n",
      "Epoch 96, Train Accuracy: 99.48333740234375, Domain Accuracy: 72.3007583618164, Source Test Accuracy: 97.43000030517578, Target Test Accuracy: 88.18889617919922\n",
      "Epoch 97, Train Accuracy: 99.50167083740234, Domain Accuracy: 72.30316162109375, Source Test Accuracy: 97.75, Target Test Accuracy: 86.63138580322266\n",
      "Epoch 98, Train Accuracy: 99.50666809082031, Domain Accuracy: 72.30741119384766, Source Test Accuracy: 97.41999816894531, Target Test Accuracy: 88.49839782714844\n",
      "Epoch 99, Train Accuracy: 99.50167083740234, Domain Accuracy: 72.3157730102539, Source Test Accuracy: 97.5999984741211, Target Test Accuracy: 88.90774536132812\n",
      "Epoch 100, Train Accuracy: 99.47166442871094, Domain Accuracy: 72.31845092773438, Source Test Accuracy: 97.7699966430664, Target Test Accuracy: 88.71804809570312\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "alpha = 1\n",
    "for epoch in range(EPOCHS):\n",
    "  reset_metrics()\n",
    "  \n",
    "  for domain_data, label_data in zip(domain_train_ds, train_ds):\n",
    "    \n",
    "    try:\n",
    "      train_step(label_data[0], label_data[1], domain_data[0], domain_data[1], alpha=alpha)\n",
    "     \n",
    "    #End of the smaller dataset\n",
    "    except ValueError: \n",
    "      pass\n",
    "    \n",
    "  for test_data, m_test_data in zip(test_ds,mnist_m_test_ds):\n",
    "    test_step(test_data[0], test_data[1], m_test_data[0], m_test_data[1])\n",
    "  \n",
    "  template = 'Epoch {}, Train Accuracy: {}, Domain Accuracy: {}, Source Test Accuracy: {}, Target Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_accuracy.result()*100,\n",
    "                         conf_train_accuracy.result()*100,\n",
    "                         test_accuracy.result()*100,\n",
    "                         m_test_accuracy.result()*100,))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Domain adaptation, TF2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
