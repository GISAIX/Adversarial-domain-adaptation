{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial domain adaptation in Tensorflow 2.0\n",
    "- TF2 implementation of basic adversarial technique documented here: https://arxiv.org/pdf/1409.7495.pdf\n",
    "- Source: MNIST \n",
    "- Target: MNIST-M (MNIST with random colour patches)\n",
    "- Train on MNIST and test on MNIST-M\n",
    "- Make the features of the classifier invariant to the domain to boost performance\n",
    "- Gives performance boost in accuracy on target domain from 61% to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras import Model\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline on MNIST-M\n",
    "\n",
    "Import MNIST and convert to RGB by replicating across 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.stack((x_train,)*3, axis=-1)\n",
    "x_test = np.stack((x_test,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 3), (None,)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(60000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now MNIST-M: dataset can be obtained here: https://drive.google.com/drive/folders/0B_tExHiYS-0vR2dNZEU4NGlSSW8.\n",
    "Use imageio to read the images and crop to 28 by 28, then create a second tf dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_m_train_folder = './mnist_m/mnist_m_train/'\n",
    "mnist_m_train_labels_file = './mnist_m/mnist_m_train_labels.txt'\n",
    "\n",
    "sorted_img_paths = [mnist_m_train_folder + i for i in sorted(os.listdir(mnist_m_train_folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 3), (None,)), types: (tf.int32, tf.int8)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist_m_test_y= pd.read_table(mnist_m_train_labels_file, sep=' ', header=None).iloc[:,1].values\n",
    "\n",
    "f = open(mnist_m_train_labels_file, \"r\")\n",
    "mnist_m_test_y = [int(i[-1]) for i in f.read().split('\\n')[:-1]]\n",
    "f.close()\n",
    "\n",
    "mnist_m_test_ds = tf.data.Dataset.from_tensor_slices(([(imageio.imread(i)[\n",
    "    2:-2,2:-2,:]) for i in sorted_img_paths],tf.cast(labels, tf.int8))).batch(32)\n",
    "\n",
    "mnist_m_test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAD5UlEQVR4nG1WzY4eRQysqp7X4ucUkDjwF2A5cEBCQllAEQcgARLtfps9ZLWQG6AgImWDeIAF3i7t4uBpT3/f0ppDT4/HLttlu3nr3ddJAogI2yQjovcutYiwCQCWbQApOe0F5JYSgWikFCQpNALAAsDoAEDn7wAA2AHYjrHPQxAtDeQBAHJ8WjcGQNC2JIExpFeAM9Jcs0CdzOclDGC4BWlRLtKzkNGNntKSyuoNLarXlCnhinlELKQBFprCVTBtA3PoNftaa4WKICWBpAjSGr47va9Q7KsIIPZd6UBMAsgwlAe10U11B8HlWON91luGY/qUe+cvywCyGUie2JHBKXvndy+TxAepNnp02I7Ak6szahDSBrj8L+rCfvrF5ZS3NKmVh7DdbdrMV8CgB9GVPi1DOyuZpf/k+CKRSigAEc7A2hiqswz504uTxrQEu5MktecB50qb/ACcYQEU0TnS8Ojp/TlJrTUislrqUNJCtjmN9e301+/SdgQiEi9I7n77diU+IKCRjWw03VPjqo0Mm2/efhUb32U7O0/vGXGcHF+UcwBOfvkm5ZOCpXHlvpKW3iy98f4rFSWbth1rHY5A2/buy8sU6z3Of7+f+7YWMEZHYJWLJDVIIwe1KuFzZYwEJHmmagKAIEdM9ntGfj70oJQmtTEx+MHnj1exWO1dPv9+BStkcNJGYs/XzfjNNdc9yUdP79lOw7Yj4u4nZ60xtXNa1fVsq4EyZDQw9wwzvAiNbqQmtjz+44eISFLlc3y0k0Q5HzWo7UFUDrLVHam11lrTWDdw+ee/fpzL3kEwqoxm7Otvb91+rdKYLJpS4pIuGS4E0Og7H5zXRHp2fTpUH1JjmTvXTJiJOZgz8dWHp7YDyq6HdVjujcIZ4jKEkl7bpCyltTk+ekgyDFtZJdkxnv+9a1lfYPasHO5EA7zkzxmcUjd63Dotjo8eJm3IRk7DDri63m29YRu6GwOX7KvkXkwkpcY7Hz3IzfgxpwRzgF1d70iCYYBYNmaD2TJtL5XuClzuP3vvnrRxrHzqEYCurs8qK6M/ezrJGGDNwRToZvvTt7/G2kQDoymVjT//uQCiokeyUVgDP65WzniA5DKXOKlip93JZSbYi3+fRLxUA31Q5JCULdIrjrUmwuY7H9+SRLYtPqax1Q5JRLdtdJBU2jMAgZLaxP3guA1WJc8c2FjsmRW9/FDeqHC4ZvoDGBc5BCCBAukQvO4Fqq5pwxVtDVwADRrZxGZ82r/ACVhm7DnNA1tjGSmJ/AQEViICgEYAZvgyXtoEDJNcEgIMSZZsy3kDwdRbCBLuI08jvXu3kL27Tyba9n9tQBXsew5J2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAECklEQVR4nHVWy44cRRCMyKz2rj1ai4uROCCDr3BHNifzJfwHP8EPISMkLHFGyBcE8gWEEZIR7HOmMjhkVXVNj6nD7nQ9MiMjI7OKX371NUmSAEiaGUmD2Ic5uA6RNEES2oj8lxbGGBtKKTZNKQIANDmQjAQtunsEYpgjHYBUAeXksXuU8/Pz/Ja0LkSbIdlWIwBExIgjUY8xwx+fkoo7c+fRDkBSREzBuiQgAAHMpWHr1EGfYTHPKUAGBmRKUgAzG8FtGJ9JGJ9HHHRPpRgDAgQKkBCAlP6JHirYDtqGhA0h02BSWqYwIRHQoHccI5kONgDH2TG/Cdp9KbQOEyIhQJIRQLdFSMq/lguc2KB/8Pp70QD88eFnHR9MStBlkx8Aj379AdSfj58OXK0gzDK3I7GnjI+gzZJMvcOBJIVoIIYJCQK6YNSyI+DR65eREpEGXSSJrKF3OUiYHcKavc1kOsvKkPTXx5/PEYy/JdMyZyki0tCQ82luVzRVDa1lSPDkvo/S+0HzsfvpRQaxcbxBt6VUa22bMO8s70Q3DmziHWjS0NmrF9H7z8rehElS6e3lKBNJ1KbPzDDTwXT2SFcDDYByqOHuisjm8yCqmZn57GCczB/3f/ymz7TC+ffT5yuTTgKMxluRVGtN1O6+LAvJGkPILSt5uNY60v5/RTB/SiqlNJaGxcPhQPLhq2/73jU1xQ2AOFEtXn7yHCfJrwAICiUibm5uEntEvHny7P1fXrr7Rj+S3jx51jIEAnjv5+/SwWjdp9EQKLXq8vJ6WRb3pVaZ2e+Pn9Js28VIqkWpzHNbUei4SYAj6gBKYh8JTPkzDU1iPeX9tAXMO4eai4Ddbnd9fX1UzGIdzSc0jhW2Tk/SbJQI19Y7WV9VdO/s7Pb21t1bNydhedGlv/nC2t5o3dz6DFAy1GGVq9u7JXS3r3Zz5+7pPFjNzLNlqo4bKQWUd8YgqEaYeRwRqCayqCUi3r59S/JeRMq8lBK5nDcKNSJws4iGLV9QWRyzkFptJyagnN/fXV3ePNjt7p3fj4iIoLujpnLmfCZ7w3qtNdXs7sfvjzW+yF4EI4y1CgbAstBoU8D9ZyLoMDOy/HQgAMvPWWzl738uRd9XHfY3LFbooXCCQdnaxr3dmu7e0v/bR1+QCphQi5V0MKqDAsnQoVxdXV1cPCxlqbVGaM/KfF9EzcecRKlWuhlwV2ViMBgmg6OvCly7Mql0YGaFtGzOEXnziqgkDYIqDQoJIoICRYUooKcRIMxFazdNZgvhRgGHULm4uHD3/X4fgWVZUjRuiAiGCJpT6pcJmz+Hg4wagMysRu3tMr0YxIypuFsqwR1AKAjgkM2wa35oyQSzImNTpTmAChgoIWrPuaH2V8V/ik1EEpPH6KwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  image_path = sorted_img_paths[n]\n",
    "  display.display(display.Image(image_path))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine MNIST and MNIST-M images, to get the channel stats for normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_images = np.vstack((x_train, [(imageio.imread(i)[2:-2,2:-2,:]) for i in sorted_img_paths]))\n",
    "channel_mean = all_domain_images.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(Model):\n",
    "  def __init__(self):\n",
    "    super(BaselineModel, self).__init__()\n",
    "    \n",
    "    self.normalise = lambda x: (tf.cast(x, tf.float64) - channel_mean) / 255.0\n",
    "    self.conv1 = Conv2D(32, 5, activation='relu')\n",
    "    self.conv2 = Conv2D(64, 5, activation='relu')\n",
    "    self.maxpool = MaxPool2D(2)\n",
    "    self.flatten = Flatten()\n",
    "    \n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "    \n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.normalise(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "\n",
    "    return self.d2(x)\n",
    "\n",
    "model = BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a separate loss accumulator for each train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "m_test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "m_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(mnist_images, labels, mnist_m_images, labels2):\n",
    "  predictions = model(mnist_images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "  predictions = model(mnist_m_images)\n",
    "  t_loss = loss_object(labels2, predictions)\n",
    "    \n",
    "  m_test_loss(t_loss)\n",
    "  m_test_accuracy(labels2, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on MNIST, evaluate on MNIST and MNIST-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 96.97333526611328, Source Test Accuracy: 98.73999786376953, Target Test Accuracy: 61.861019134521484\n",
      "Epoch 2, Train Accuracy: 97.93917083740234, Source Test Accuracy: 98.56500244140625, Target Test Accuracy: 59.24021530151367\n",
      "Epoch 3, Train Accuracy: 98.38555145263672, Source Test Accuracy: 98.66333770751953, Target Test Accuracy: 58.70606994628906\n",
      "Epoch 4, Train Accuracy: 98.64458465576172, Source Test Accuracy: 98.71749877929688, Target Test Accuracy: 59.197784423828125\n",
      "Epoch 5, Train Accuracy: 98.82566833496094, Source Test Accuracy: 98.76399993896484, Target Test Accuracy: 59.52476119995117\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_data, m_test_data in zip(test_ds,mnist_m_test_ds):\n",
    "    test_step(test_data[0], test_data[1], m_test_data[0], m_test_data[1])\n",
    "    \n",
    "  template = 'Epoch {}, Train Accuracy: {}, Source Test Accuracy: {}, Target Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_accuracy.result()*100,\n",
    "                         m_test_accuracy.result()*100,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain confusion\n",
    "Build separate components so that distinct sets of gradients are easily accessed:\n",
    "\n",
    "- feature generator\n",
    "- label classifier \n",
    "- domain classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(Model):\n",
    "  def __init__(self):\n",
    "    super(FeatureGenerator, self).__init__() \n",
    "    self.normalise = lambda x: (tf.cast(x, tf.float64) - channel_mean) / 255.0\n",
    "    self.conv1 = Conv2D(32, 5, activation='relu')\n",
    "    self.conv2 = Conv2D(64, 5, activation='relu')\n",
    "    self.maxpool = MaxPool2D(2)\n",
    "    self.flatten = Flatten()\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.normalise(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.maxpool(x)\n",
    "\n",
    "    return self.flatten(x)\n",
    "\n",
    "feature_generator = FeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPredictor(Model):\n",
    "  def __init__(self):\n",
    "    super(LabelPredictor, self).__init__() \n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "    \n",
    "\n",
    "  def call(self, feats):  \n",
    "    feats = self.d1(feats)\n",
    "\n",
    "    return self.d2(feats)\n",
    "\n",
    "label_predictor = LabelPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainPredictor(Model):\n",
    "  def __init__(self):\n",
    "    super(DomainPredictor, self).__init__()   \n",
    "    self.d3 = Dense(64, activation='relu')\n",
    "    self.d4 = Dense(2, activation='softmax')\n",
    "\n",
    "  def call(self, feats):\n",
    "    feats = self.d3(feats)\n",
    "    \n",
    "    return self.d4(feats)\n",
    "\n",
    "domain_predictor = DomainPredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make second training dataset of MNIST and MNIST-M images and their respective domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_domain_labels = np.ones([len(x_train)])\n",
    "mnist_m_domain_labels = np.zeros([len(sorted_img_paths)])\n",
    "all_domain_labels = np.hstack((x_train_domain_labels, mnist_m_domain_labels))\n",
    "\n",
    "domain_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (all_domain_images, tf.cast(all_domain_labels, tf.int8))).shuffle(60000).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate optimizers to allow different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "f_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminative losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "m_test_loss = tf.keras.metrics.Mean(name='m_test_loss')\n",
    "m_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='m_test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_train_loss = tf.keras.metrics.Mean(name='c_train_loss')\n",
    "conf_train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='c_train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three sets of parameters to update, one for each component of the model. Label and domain classifiers are updated in the usual way. Parameters of the feature generator are updated using the standard gradient backpropagated from the label classifier, summed with the reverse of the gradient from the domain classifier; the feature generator learns to confound the domain classifier, resulting in domain invariant features which should be useful for general performance.\n",
    "\n",
    "\n",
    "<img src=\"DANN_architecture.png\" style=\"width: 600px;\">\n",
    "\n",
    "\n",
    "Image taken from: https://arxiv.org/pdf/1409.7495.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels, images2, domains, alpha):\n",
    "    \n",
    "  \"\"\"\n",
    "  i. images = batch of source images\n",
    "  ii. labels = corresponding labels\n",
    "  iii. images2 = batch of source and target images\n",
    "  iv. domains = corresponding domain labels\n",
    "  v. alpha = weight attributed to the domain loss\n",
    "  \"\"\"\n",
    "    \n",
    "  ## Update the generator and the classifier\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    features = feature_generator(images)\n",
    "    l_predictions = label_predictor(features)\n",
    "    features = feature_generator(images2)\n",
    "    d_predictions = domain_predictor(features)\n",
    "    label_loss = loss_object(labels, l_predictions)\n",
    "    domain_loss = loss_object(domains, d_predictions)\n",
    "    \n",
    "  f_gradients_on_label_loss = tape.gradient(label_loss, feature_generator.trainable_variables)\n",
    "  f_gradients_on_domain_loss = tape.gradient(domain_loss, feature_generator.trainable_variables)    \n",
    "  f_gradients = [f_gradients_on_label_loss[i] - alpha*f_gradients_on_domain_loss[\n",
    "      i] for i in range(len(f_gradients_on_domain_loss))]\n",
    "\n",
    "    \n",
    "  l_gradients = tape.gradient(label_loss, label_predictor.trainable_variables)\n",
    "\n",
    "  f_optimizer.apply_gradients(zip(f_gradients+l_gradients, \n",
    "                                  feature_generator.trainable_variables+label_predictor.trainable_variables)) \n",
    "    \n",
    "    \n",
    "  ## Update the discriminator: Comment this bit to complete all updates in one step. Asynchronous updating \n",
    "  ## seems to work a bit better, with better accuracy and stability, but may take longer to train    \n",
    "  with tf.GradientTape() as tape:\n",
    "    features = feature_generator(images2)\n",
    "    d_predictions = domain_predictor(features)\n",
    "    domain_loss = loss_object(domains, d_predictions)\n",
    "  #####\n",
    "    \n",
    "  d_gradients = tape.gradient(domain_loss, domain_predictor.trainable_variables)  \n",
    "  d_gradients = [alpha*i for i in d_gradients]\n",
    "  d_optimizer.apply_gradients(zip(d_gradients, domain_predictor.trainable_variables)) \n",
    "    \n",
    "    \n",
    "  train_loss(label_loss)\n",
    "  train_accuracy(labels, l_predictions)\n",
    "  conf_train_loss(domain_loss)\n",
    "  conf_train_accuracy(domains, d_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(mnist_images, labels, mnist_m_images, labels2):\n",
    "  features = feature_generator(mnist_images)\n",
    "  predictions = label_predictor(features)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "  features = feature_generator(mnist_m_images)\n",
    "  predictions = label_predictor(features)\n",
    "  t_loss = loss_object(labels2, predictions)\n",
    "    \n",
    "  m_test_loss(t_loss)\n",
    "  m_test_accuracy(labels2, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate. May need > 100 epochs for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 97.89350128173828, Domain Accuracy: 76.03472900390625, Source Test Accuracy: 96.718017578125, Target Test Accuracy: 79.03201293945312\n",
      "Epoch 2, Train Accuracy: 97.9066390991211, Domain Accuracy: 76.04347229003906, Source Test Accuracy: 96.72892761230469, Target Test Accuracy: 79.128662109375\n",
      "Epoch 3, Train Accuracy: 97.92040252685547, Domain Accuracy: 76.05339050292969, Source Test Accuracy: 96.73681640625, Target Test Accuracy: 79.20795440673828\n",
      "Epoch 4, Train Accuracy: 97.93437194824219, Domain Accuracy: 76.06088256835938, Source Test Accuracy: 96.74762725830078, Target Test Accuracy: 79.30022430419922\n",
      "Epoch 5, Train Accuracy: 97.9473648071289, Domain Accuracy: 76.06851196289062, Source Test Accuracy: 96.75704193115234, Target Test Accuracy: 79.39383697509766\n",
      "Epoch 6, Train Accuracy: 97.96015930175781, Domain Accuracy: 76.07662200927734, Source Test Accuracy: 96.76724243164062, Target Test Accuracy: 79.47990417480469\n",
      "Epoch 7, Train Accuracy: 97.97249603271484, Domain Accuracy: 76.08251190185547, Source Test Accuracy: 96.7784652709961, Target Test Accuracy: 79.55400085449219\n",
      "Epoch 8, Train Accuracy: 97.98515319824219, Domain Accuracy: 76.09090423583984, Source Test Accuracy: 96.7865219116211, Target Test Accuracy: 79.62869262695312\n",
      "Epoch 9, Train Accuracy: 97.99711608886719, Domain Accuracy: 76.09749603271484, Source Test Accuracy: 96.79680633544922, Target Test Accuracy: 79.71707916259766\n",
      "Epoch 10, Train Accuracy: 98.00873565673828, Domain Accuracy: 76.1036376953125, Source Test Accuracy: 96.805419921875, Target Test Accuracy: 79.80431365966797\n",
      "Epoch 11, Train Accuracy: 98.02033233642578, Domain Accuracy: 76.10891723632812, Source Test Accuracy: 96.81536865234375, Target Test Accuracy: 79.87195587158203\n",
      "Epoch 12, Train Accuracy: 98.03218841552734, Domain Accuracy: 76.111572265625, Source Test Accuracy: 96.8243408203125, Target Test Accuracy: 79.95780944824219\n",
      "Epoch 13, Train Accuracy: 98.04373168945312, Domain Accuracy: 76.1196517944336, Source Test Accuracy: 96.8330078125, Target Test Accuracy: 80.03762817382812\n",
      "Epoch 14, Train Accuracy: 98.05510711669922, Domain Accuracy: 76.12628936767578, Source Test Accuracy: 96.84282684326172, Target Test Accuracy: 80.1180191040039\n",
      "Epoch 15, Train Accuracy: 98.06617736816406, Domain Accuracy: 76.13345336914062, Source Test Accuracy: 96.85343933105469, Target Test Accuracy: 80.19049835205078\n",
      "Epoch 16, Train Accuracy: 98.07749938964844, Domain Accuracy: 76.13835906982422, Source Test Accuracy: 96.86270141601562, Target Test Accuracy: 80.27156829833984\n",
      "Epoch 17, Train Accuracy: 98.08815002441406, Domain Accuracy: 76.14557647705078, Source Test Accuracy: 96.8730697631836, Target Test Accuracy: 80.34908294677734\n",
      "Epoch 18, Train Accuracy: 98.09931182861328, Domain Accuracy: 76.1534652709961, Source Test Accuracy: 96.88163757324219, Target Test Accuracy: 80.4222640991211\n",
      "Epoch 19, Train Accuracy: 98.10974884033203, Domain Accuracy: 76.16082763671875, Source Test Accuracy: 96.88573455810547, Target Test Accuracy: 80.48184967041016\n",
      "Epoch 20, Train Accuracy: 98.12042236328125, Domain Accuracy: 76.16851043701172, Source Test Accuracy: 96.89169311523438, Target Test Accuracy: 80.54358673095703\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "   \n",
    "for epoch in range(EPOCHS):\n",
    "  for domain_data, label_data in zip(domain_train_ds, train_ds):\n",
    "    \n",
    "    try:\n",
    "      train_step(label_data[0], label_data[1], domain_data[0], domain_data[1], alpha=1)\n",
    "     \n",
    "    #End of the smaller dataset\n",
    "    except ValueError: \n",
    "      pass\n",
    "    \n",
    "  for test_data, m_test_data in zip(test_ds,mnist_m_test_ds):\n",
    "    test_step(test_data[0], test_data[1], m_test_data[0], m_test_data[1])\n",
    "  \n",
    "  template = 'Epoch {}, Train Accuracy: {}, Domain Accuracy: {}, Source Test Accuracy: {}, Target Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_accuracy.result()*100,\n",
    "                         conf_train_accuracy.result()*100,\n",
    "                         test_accuracy.result()*100,\n",
    "                         m_test_accuracy.result()*100,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
